[Previous](/docs/page00015.md) | [Next](/docs/page00017.md)

# Understanding the Ingestion Payload: Sensors vs. Predictions

A key aspect of the LEAFCLOUD system is how it handles data ingestion. In a real-world scenario, NPK predictions (Nitrogen, Phosphorus, Potassium) often come from computationally intensive models (like CNNs) that might take time to run. We don't want the IoT device waiting for these predictions before it can confirm data delivery.

Therefore, we use an **Asynchronous Background Task** workflow.

## The Workflow

1.  **Sensors Send Data:** The IoT device sends *only* the raw sensor data (EC, pH, Temp, Image) to the `POST /api/v1/readings` endpoint.
2.  **Server Acknowledges:** The server validates the data and immediately returns a `202 Accepted` response. This tells the device "I got it, you can go back to sleep."
3.  **Background Processing:** *After* sending the response, the server spins up a background task.
4.  **Prediction & Save:** This task runs the prediction model (calculating NPK from the image/sensors) and then saves the *complete* record to the database.

## The `ReadingInput` Model

This model defines the schema for the data the API expects to receive from the sensors. Notice it **excludes** the NPK values.

```python
# From main.py

class ReadingInput(BaseModel):
    timestamp: datetime
    plant_id: str
    lettuce_image_url: str
    # Sensors Only
    ec: float
    ph: float
    temp_c: float
```

## How to Run the Background Job

The beauty of FastAPI's `BackgroundTasks` is that you don't need to run a separate worker process (like Celery or Redis) for simple use cases. The background job is managed automatically by the main application process.

### 1. Start the Server
Simply run the server as usual:
```bash
uvicorn main:app --reload
```

### 2. Trigger the Job
Send a POST request to the endpoint. You will see the server respond immediately, and then you will see the background task logs appear in the console *afterward*.

**Example Request (using `curl`):**
```bash
curl -X 'POST' \
  'http://127.0.0.1:8000/api/v1/readings' \
  -H 'Content-Type: application/json' \
  -d '{
  "timestamp": "2023-10-27T10:00:00",
  "plant_id": "plant-001",
  "lettuce_image_url": "http://example.com/image.jpg",
  "ec": 1.2,
  "ph": 6.5,
  "temp_c": 24.0
}'
```

**Expected Console Output:**
```text
INFO:     127.0.0.1:56890 - "POST /api/v1/readings HTTP/1.1" 202 Accepted
Background Task: Saved reading for plant-001 with NPK predictions.
```

The first line shows the HTTP response. The second line confirms the background job ran successfully.

## Customizing the Prediction Logic

To replace the "Mock" prediction with your real CNN model, edit the `mock_predict_npk` function in `main.py`:

```python
def mock_predict_npk(image_url: str, ec: float, ph: float, temp: float):
    # 1. Download image from image_url
    # 2. Preprocess image
    # 3. Run your model: model.predict(...)
    # 4. Return real values
    return { "n_ppm": ..., "p_ppm": ..., "k_ppm": ... }
```

[Previous](/docs/page00015.md) | [Next](/docs/page00017.md)
